\chapter{Containervirtualisierung}

Dieses Kapitel beschreibt mit Containervirtualisierung eine effektive Möglichkeit Microservices mit allen Abhängigkeiten effizient und robust zu betreiben. Es handelt sich dabei eigentlich um keine neue Technologie, aber eine Implementierung mit dem Namen \textit{Docker} löste eine Art Renaissance dieser Virtualisierungsart aus. Mittlerweile ist \textit{Docker} eine allgegenwärtige Methode für die Bereitstellung von Software aller Art.

Eine Microservices"=Architektur ist nicht nur aus Softwareentwicklungssicht herausfordernd, sondern auch aus Infrastruktursicht. Jeder Microservice muss unabhängig ausgerollt und skaliert werden können. Nur so kann diese Architektur auch die in Abschnitt \ref{sec:ms-advantages} beschriebenen Vorteile entfalten. In diesem Kapitel wird Betriebssystemvirtualisierung mittels Containern vorgestellt, die eine effiziente Verteilung von Anwendungen und deren Abhängigkeiten ermöglichen. Im Unterschied zu klassischer Virtualisierung bietet dieser Ansatz wesentlich kürzere Bereitstellungszeiten und eine effektivere Nutzung von Ressourcen.

Jeder Service hat bestimmte Voraussetzungen an seine Infrastrukturumgebung. Dazu zählen externen Bibliotheken, Konfigurationen und selbstverständlich eine Laufzeitumgebung, wie \zB Java, .NET oder Python. Man könnte versuchen über \textit{Infrastructure-as-Code} die für einen Service notwendigen Abhängigkeiten zu installieren. Ein alternativer Ansatz ist den Service mit seinen Abhängigkeiten in ein Betriebssystemabbildung -- \textit{engl. Image} -- zu verpacken \cite[113]{newman2015building}. Anstelle einer ausführbaren Anwendung, wird einfach ein vollständiges Abbild eines virtuellen Servers erstellt, der die Anwendung beinhaltet.

\section{Unveränderbarer Server}

Anstatt die Konfiguration eines Servers zu ändern, kann man ihn auch stoppen und einen neuen Server mit aktualisierter Konfiguration wieder starten. Was sich anfänglich sehr aufwändig und unsinnig anhört, ist heute aus gutem Grund gängige Praxis. Die Firma \textit{Netflix} war eines der ersten Unternehmen, das diesen Ansatz praktizierte \cite{NflxLegos}. Laut eigenen Angaben, konnten sie dadurch die Reproduzierbarkeit und Stabilität ihres Softwareauslieferungsprozess stark verbessern. Zurückzuführen ist das auf die Tatsache, dass die in der Testumgebung validierten Artefakte identisch zu den im Produktivsystem eingesetzten sind. Des weiteren gibt es keine Möglichkeit, wie eine Konfigurationsänderung unabsichtlich in ein Produktivsystem gelangen kann, ohne dass diese durch eine Reihe von Tests validiert wurde.

Unter einem unveränderbaren Server versteht man also eine Ressource, die niemals verändert, sondern nur durch eine aktualisierte Version ersetzt wird \cite{ImmutableServer}. Die in diesem Kapitel betrachtete Containertechnologie \textit{Docker} unterstützt diesen Ansatz sehr gut und ist darüber hinaus auch noch effizienter als klassische Virtualisierung.

\section{Arten von Virtualisierung}

Vor dem Einstieg in Containertechnologien lohnt sich ein genauerer Blick auf verschiedene Virtualisierungstechniken. Nur wer die Eigenschaften der verschieden Systeme kennt, kann objektiv entscheiden, in welcher Situation welche Technologie vorteilhaft ist.

Unter Virtualisierung versteht man die Illusion mehrere virtuelle und voneinander unabhängige Server auf einem einzigen physischen System auszuführen. Zum einen ermöglicht das eine effektivere Nutzung von Ressourcen und zum anderen die Möglichkeit Server per Software zu verwalten. Über die Jahre wurden viele verschiedene Arten von Virtualisierung entwickelt. \cite{VirtualizationBasics} und \cite{Smith:2005:AVM:1069588.1069632} geben eine mögliche Klassifizierungen dieser Ansätze anhand ihrer Architektur. Die nächsten Abschnitte beschreiben aus diesen beiden Werken die für den Kontext dieser Arbeit relevanten Arten.

\subsubsection{Vollständige Virtualisierung}

Bei der \textit{vollständigen Virtualisierung} ermöglicht der sogenannte Hypervisor den Gastbetriebssystemen den Zugriff auf die Hardware. Die Gastsysteme sind unveränderte Betriebssysteme die keine Kenntnis darüber haben, dass sie virtualisiert sind. Für jeden Gast wird sozusagen eine vollständige Hardwareumgebung simuliert. Dieser Ansatz schützt die Gastsysteme gegenseitig sehr effektiv, er ist ziemlich aufwändig, da jedes Gastsystem ein vollständiges Betriebssystem ist.

\subsubsection{Paravirtualisierung}

Wenn das Gastsystem Kenntnis über die Virtualisierung hat, dann spricht man von \textit{Paravirtualisierung}. Das Gastsystem verwendet sogenannte \textit{Hypercalls} um direkt mit dem Hypervisor zu interagieren. Damit lässt sich eine Performanzverbesserung erzielen, erfordert aber ein adaptiertes Gastbetriebssystem. Diese Art der Virtualisierung kommt \zB in der \textit{Microsoft Azure} Cloud zum Einsatz \cite[30]{Krishnan10}. Dort wird das Gastbetriebssystem als aufgeklärt -- \textit{engl. enlightend} -- bezeichnet.

\subsubsection{Prozessorunterstützte vollständige Virtualisierung}

Für die \textit{prozessorunterstützte vollständige Virtualisierung} greift der Hypervisor auf spezielle Prozessorfunktionen zurück. Der Befehlssatz dieser Prozessoren wurde spezielle für Virtualisierungsszenarien erweitert, um eine Geschwindigkeitssteigerung zu erzielen und die Aufgaben des Hypervisors zu erleichtern. Durch die damit erreichte Komplexitätsreduktion der Hypervisorimplementierung sind diese viel einfacher und robuster.

\subsubsection{Betriebssystemvirtualisierung}

Die \textit{Betriebssystemvirtualisierung} unterscheidet sich stark von den anderen Arten. Hier gibt es keinen Hypervisor und auch die Gastsysteme sind keine vollständigen Betriebssysteme. Stattdessen werden sogenannte Container innerhalb eines Betriebssystems virtualisiert. Diese Art erfordert nur eine Betriebssystem und ist dementsprechend auch schneller und Ressourcensparender. Eine wesentliche Einschränkung ist aber, dass die Container und das Wirtsystem vom selben Betriebssystem sein müssen.

\section{Isolation versus Effizienz}
\label{sec:isolation-vs-efficiencys}

Virtualisierung ist immer ein Kompromiss zwischen Effizient und Isolation. Jede Art zieht die Grenzen zwischen diesen beiden Eigenschaften an einem anderen Punkt. Die Effizient lässt sich einfach Anhand quantitativer Kriterien, wie Durchsatz oder Latenzzeiten festmachen. Bei der Isolation gestaltet sich die Situation schwieriger. In \cite{Soltesz:2007:COS:1272996.1273025} werden dazu folgende Kriterien herangezogen:

\begin{itemize}
	\item \textit{Fehlerisolation} ist gegeben, wenn ein Fehler in einem Gastsystem kein anderes Gastsystem beeinflusst.
	\item \textit{Ressourcenisolation} stellt sicher, dass die vorhandenen Ressourcen gerecht \bzw kontrollierbar auf die Gastsysteme aufgeteilt werden.
	\item \textit{Sicherheitsisolation} sorgt für die Sicherheit zwischen Gastsystemen. Sicherheitslücken treten vermehrt auf, wenn verschiedene Aspekte zwischen Gastsystemen geteilt werden. Dazu zählen \zB das Dateisystem, virtueller Adressraum, Netzwerk \usw
\end{itemize}

Hypervisorvirtualisierung, auch gerne als Hardwarevirtualisierung bezeichnet, bietet bessere Isolation als Betriebssystemvirtualisierung, ist aber wesentlich ineffizienter. In vielen Szenarien, wie einer Microservice"=Architektur, ist eine strenge Isolation nicht notwendig, sondern kann gegen Effizienz eingetauscht werden. Darum ist Betriebssystemvirtualisierung mit Containern in diesen Fällen gut geeignet.

\section{Docker}

Die zur Zeit bekannteste Betriebssystemvirtualisierungssoftware ist \textit{Docker}. Im Gegensatz zur Hardwarevirtualisierung wird auf die Emulation einer Hardwareumgebung verzichtet. Der Verzicht auf diese Indirektionsschicht bringt entscheidende Geschwindigkeitsverbesserungen.

Im Gegensatz zu den anderen Virtualisierungstechniken, steht bei \textit{Docker} die Auslieferung von Software im Vordergrund. Ähnlich zu einer Paketverwaltungssoftware bietet \textit{Docker} eine zentrale Stelle um Software zu beziehen. \textit{Docker} erleichtert den Bezug, die Installation und die Aktualisierung von Software.

\subsection{Begriffserklärung}

Im Zusammenhang mit \textit{Docker} gibt es einige wichtige Begriffe. Die nachfolgende Liste bietet einen kurzen Überblick über die drei wichtigsten davon:

\begin{itemize}
	\item Ein \textit{Image} ist die Vorlage für einen Container.
	\item Das \textit{Dockerfile} ist eine textuelle Beschreibung eines Images. Aufgrund dieser Beschreibung wird schlussendlich das Image erstellt.
	\item Ein \textit{Container} ist ein Instanz eines Images zur Laufzeit. Im Grunde ist ein Container nichts anderes als ein virtuelles Betriebssystem. Beliebig viele Container vom selben Image können gleichzeitig ausgeführt werden.
\end{itemize}

Der nächste Abschnitt setzt die gerade definierten Begriffe in Kontext und beschreibt den grundsätzlichen Aufbau von \textit{Docker}. Darüber hinaus werden die signifikanten Unterschiede zu Hardwarevirtualisierung hervorgehoben.

\subsection{Docker"=Architektur}

\textit{Docker} implementiert eine klassische Client"=Server"=Architektur. Der Serverteil wird als \textit{Docker"=Engine} oder \textit{Docker"=Deamon} bezeichnet. Er interagiert mit dem Betriebssystem um die tatsächliche Containervirtualisierung zu realisieren.

Der Server bietet eine REST"=Schnittstelle an, über die Klienten unterschiedlichster Art mit dem Server kommunizieren können. Somit können sie \zB Images erstellen, Container starten, stoppen oder löschen. Um ein Image zu erstellen, sendet der Client die Beschreibung in Form des \textit{Dockerfile} und die benötigten Dateien an den \textit{Docker"=Deamon}. Dieser erstellt aufgrund der Beschreibung ein Image, dass alle benötigten Abhängigkeiten bereits inkludiert. Auf Basis dieses Images kann der Client beliebig viele Container starten. In Abbildung \ref{fig:docker-arch} ist dieser Ablauf noch einmal visuell dargestellt.

\begin{figure}[!hbt]%
\centering
\includegraphics[width=\columnwidth]{docker-arch.pdf}%
\caption{Docker-Architektur}%
\label{fig:docker-arch}%
\end{figure}

Die genaue technische Umsetzung der Virtualisierung mit \textit{Docker} übersteigt den Rahmen dieser Arbeit. Der folgende Abschnitt beschreibt nur einen komprimierten Überblick.

\subsection{Voraussetzungen für Betriebssystemvirtualisierung}

Containervirtualisierung isoliert die einzelnen Container nur auf Betriebssystemebenen. Die in einem Container gestarteten Anwendungen sind im Prinzip gewöhnliche Betriebssystemprozesse im Wirtsystem. Die nachfolgenden Abschnitt basieren auf \cite{Merkel:2014:DLL:2600239.2600241}, sowie \cite{DBLP:journals/corr/Bui15} und beschreiben einige Betriebssystemkomponenten die für die Virtualisierung verantwortlich sind.

\subsubsection{Namensräume}

\textit{Namensräume} bezeichnen im Betriebssystem \textit{Linux} eine Technologie, mit der Betriebssystemressourcen gruppiert und somit voneinander isolieren werden können. Dazu zählen beispielsweise Prozesse, Netzwerkverbindungen, Dateisystem und \usw Diese Technologie stellt somit die Isolation zwischen Container und auch zum Wirtsystem sicher.

\subsubsection{Kontrollgruppen}

Wie Abschnitt \ref{sec:isolation-vs-efficiencys} schon dargestellt hat, ist eine faire Ressourcenaufteilung zwischen Containern sehr wichtig. Linux biete dafür das Konzept der Kontrollgruppen. Diese Überwachen den Ressourcenverbrauch von Containern und können gegebenenfalls den Verbrauch limitieren.

\subsubsection{Überlagerte Dateisysteme}

Durch die Verwendungen eines spezielle Dateisystems, kann \textit{Docker} viele Daten zwischen Containern teilen und somit viel Speicherplatz sparen. Die Grundidee ist mehrere Schichten eines Dateisystems in eine einzige logische Schicht zu vereinen. Jede Schicht, außer die oberste, ist unveränderbar. Änderungen einer Datei in einer Schicht überdecken die gleiche Datei in niedrigeren Schichten.

Für beliebig viele Containerinstanzen ist somit nur eine einzige Kopie des Images notwendig. Mit dieser Technik ist also eine enorme Speicherersparnis möglich, ohne die Isolation zu kompromittieren. Je nach Betriebssystem gibt es verschiedene Implementierungen dieses Konzepts. Zwei der bekanntesten Implementierungen sind das \textit{Advanced Multi-Layered Unification File\-system} und das \textit{OverlayFS}.

\subsection{Docker Beispiel}

Programm~\ref{prog:dockerfile} zeigt eine Beispiel für ein \textit{Dockerfile}, dass ein Image mit einem Web"=Service erstellt. Im Basis"=Image ist bereits .NET Core -- eine Abhängigkeit des Web"=Services -- vorinstalliert. Im Prinzip erhält es alle notwendigen Schritte, um den Web"=Service auf einem leeren System zu installieren und zu konfigurieren.

\begin{program}[!hbt]
\caption{Beispiel für ein Dockerfile}
\label{prog:dockerfile}
\begin{DockerCode}
FROM microsoft/dotnet:1.1.1-runtime
COPY published app
WORKDIR app
ENV ASPNETCORE_URLS http://+:80 
EXPOSE 80
ENTRYPOINT [ "dotnet", "mywebapi.dll" ]
\end{DockerCode}
\end{program}

Die in Programm~\ref{prog:dockercommands} angeführten Kommandozeilenbefehle, erzeugen aus der Imagebeschreibung aus Programm~\ref{prog:dockerfile} ein ausführbares Image.

\begin{program}[!hbt]
\caption{Docker Kommandozeilenbefehle}
\label{prog:dockercommands}
\begin{GenericCode}
docker build -t sample-image .
docker run -d --rm -p 5000:80 sample-image
\end{GenericCode}
\end{program}

\section{Containerorchestrierung}

Einen Container auf nur einem Server zu betreiben ist eine triviale Aufgaben, aber hunderte Container auf einem Cluster mit mehreren Servern, ist eine ungleich schwierigeres Unterfangen. Dieses Szenario ist in einer Microservices"=Architektur eher die Regel als die Ausnahme. Um diese Herausforderungen zu bewältigen, wurden eine Vielzahl von sogenannten Containerorchestrierungswerkzeugen und Containerplattformen entwickelt \bzw werden noch immer entwickelt. Eine wichtige Funktion von diesen Werkzeugen ist es mehrere Container zu einer logischen Einheit zusammenzuschließen, sodass diese auch als Einheit verwaltet werden kann. Des weiteren bieten diese Werkzeuge eine Abstraktion der tatsächlichen Infrastruktur. So können mehrere Server zu einem Cluster verbunden und dieser als zusammenhängende Plattform betrachtet werden. Die Technologielandschaft rund um Containerorchestrierung und Containerplattformen ist sehr breit und befindet sich noch stark im Aufbau. Eine genaue Betrachtung dieses große Bereich würde das Ausmaß dieser Arbeit übersteigen. Dennoch ist es für eine Arbeit wie diese, die sich mit dem Thema Microservices auseinandersetzt, unumgänglich diesen wichtigen Teilbereich zu erwähnen. Daher werden nachfolgend zumindest einige grundlegende Aspekte von Containerorchestrierung im Bezug auf Microservices dargestellt, die sich hauptsächlich auf \cite{ContainerOrcaWars} beziehen. 

\subsection{Funktionalität}

Die Hauptaufgaben eines Containerorchestrierungswerkzeuges sind Maschinenbelegungsplanung, Ressourcen- und Serviceverwaltung. All diese Funktionen ermöglichen eine Reihe nicht"=funktionaler Eigenschaften wie Skalierbarkeit, Verfügbarkeit oder Portabilität. Je nach Produkt unterscheidet sich der Funktionsumfang und die Umsetzung der einzelnen Funktion.

\subsubsection{Maschinenbelegungsplanung}

Ein Orchestrierungswerkzeug muss entscheiden auf welchem Server eine oder mehrere Instanzen eines Containers erzeugt werden. Serverausfälle sollen automatisch erkannt und betroffene Container auf einem anderen Server neu gestartet werden. In manchen Fällen bieten sie auch eine Unterstützung bei der Aktualisierung von Containerversionen.

\subsubsection{Ressourcenverwaltung}

Alle Hardwareressourcen die ein Container in Anspruch nehmen kann, müssen überwacht und limitiert werden. Grundsätzlich betrifft das den Prozessor und den Hauptspeicher, aber auch persistenten Speicher und Netzwerkressourcen.

\subsubsection{Serviceverwaltung}

Mehrere Container werden zu einer einzelnen Applikation zusammengefasst, um sie gemeinsam zu verwalten. Im Zuge dessen müssen auch Abhängigkeit zwischen Containern berücksichtigt werden, um beispielsweise eine sinnvolle Startreihenfolge festzulegen. Damit schlussendlich eine Anwendung auch skalierbar und hoch verfügbar ist, sind Lastverteilungsmechanismen notwendig, die auch vom Orchestrierungswerkzeug verwaltet werden.

\subsection{Verteilte Betriebssysteme}

Ein Betriebssystem bietet Anwendungsprogrammen eine Schnittstelle zu den Systemressourcen eines Computers. Somit müssen sich Anwendungsprogramme nicht mit der tatsächlichen Interaktion mit einer konkreten Hardwarekomponente auseinandersetzten, sondern sie greifen auf die abstrakten Schnittstellen des Betriebssystems zurück. Auch Containerorchestrierungswerkzeuge können als eine Art Betriebssystem verstanden werden, jedoch in verteilter Form. Statt Anwendungsprogramme teilt ein Orchestrierungswerkzeug Container \bzw aus vielen Containern zusammengesetzte Anwendungen, auf einen mit einer Containervirtualisierungssoftware ausgestatteten Rechner zu. Der Kern dieses Systems ist die Containervirtualisierungssoftware, die auf jedem der verteilten Rechner läuft und natürlich die Orchestrierungssoftware mit den im vorherigen Abschnitt beschriebenen Funktionen. Die verteilten Rechner und ihr tatsächliches Host"=Betriebssystem stellen die Systemressourcen dar. In vielen Fällen werden auch diese Systemressourcen als virtuelle Rechner zur Verfügung gestellt. In Abbildung~\ref{fig:container-distributed-os} ist die Analogie zwischen Betriebssystemen und Containerorchestrierungswerkzeugen noch einmal dargestellt.

\begin{figure}[!hbt]%
\centering
\includegraphics[width=.6\columnwidth]{container-distributed-os}%
\caption{Vergleich eines Betriebssystems (links) und eines "`verteilten Betriebssystems"' durch Containerorchestrierung}%
\label{fig:container-distributed-os}%
\end{figure}

\subsection{Marktanalyse}

Studien wie \cite{ContainerMarketGrowth} sehen Container als einen der größten Zukunftsmärkte im Bereich Cloud"=Computing, mit einer geschätzten jährlichen Wachstumsrate von bis zu 40 Prozent bis 2020. Aufgrund dieser Zahlen ist es auch nicht verwunderlich, dass in diesen Bereich sehr viel investiert wird und dementsprechend viele Produkte auf den Markt kommen. 

Laut \cite{ContainerMarketReport} ist \textit{Docker} mit 94 Prozent in 2016 das meist verwendete System für Containervirtualisierung. Jedoch bei der Containerorchestrierung sieht selbige Studie derzeit einen ausgeglichenere Markaufteilung zwischen den Produkten \textit{Docker Swarm}, \textit{Kubernetes} und \textit{Apache Mesos}, wobei \textit{Kubernetes} die meisten Anteile dazugewinnen konnte.

\section{Zusammenfassung}

\newpage

\iffalse

- way of packaging applications (solves multi and conflicting version)
-

- cheap and fast (no indirection, union file system, ...)
- Containers are more like processes (efficient way to deliver applications) than OSs
- quite good isolation but not as good as vms
- Schliessen sich nicht aus (Docker in virtuellen maschine machen sehr viel sinn) -> ABER docker is for packeging and deployment



- Docker
  - Leightweight virtual machine
	- sandboxing
  - Technologie developed on linux and adopted in windows
	- client server arch
	- container vs vms figure
	- Dependency hell
	- container vs. hypervisor-based vms
	  - os level vs. hardware level
	- Advantages
	  - Multi version
		- missing dependencies
		- 
	- OS-Level Concepts
	  - cgroups
		- namespaces
		- union-file system
		- virtual networks
		- ...
	- Docker Architecture
	  - CLI, Rest-Service, Host
		- Registry, Hub
		- Swarm
	- Microservices
	  - Compose
		
\fi